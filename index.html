<html>
	<head>
		<title>wireframe</title>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, user-scalable=no, minimum-scale=1.0, maximum-scale=1.0">
		<link rel="stylesheet" type="text/css" href="index.css">
	</head>
	<body>
		<script src="lib/three.js"></script>
		<script src="lib/VRControls.js"></script>
		<script src="lib/three.ar.js"></script>
		<script>
			var vrDisplay, vrControls, vrFrameData, arView;

			var OBJECT_DISTANCE = 5;
			var objectsAdded = false;

			var canvas;
			var camera;
			var scene;
			var renderer;
			var object;
			var objects = [];

			var anchorManager;

			/**
			 * Use the `getARDisplay()` utility to leverage the WebVR API
			 * to see if there are any AR-capable WebVR VRDisplays. Returns
			 * a valid display if found. Otherwise, display the unsupported
			 * browser message.
			 */
			THREE.ARUtils.getARDisplay().then(function (display) {
				if (display) {
					vrFrameData = new VRFrameData();
					vrDisplay = display;
					init();
				} else {
					THREE.ARUtils.displayUnsupportedMessage();
				}
			});

			function init() {
				
				// Turn on the debugging panel
  				var arDebug = new THREE.ARDebug(vrDisplay);
  				document.body.appendChild(arDebug.getElement());

				// Setup the three.js rendering environment
				renderer = new THREE.WebGLRenderer({
					alpha: true
				});
				renderer.setPixelRatio(window.devicePixelRatio);
				renderer.setSize(window.innerWidth, window.innerHeight);
				renderer.autoClear = false;
				canvas = renderer.domElement;
				document.body.appendChild(canvas);

				scene = new THREE.Scene();

				// createSkybox();
				createLight();
				createObject();

				// Creating the ARView, which is the object that handles
				// the rendering of the camera stream behind the three.js
				// scene
				arView = new THREE.ARView(vrDisplay, renderer);

				// The ARPerspectiveCamera is very similar to THREE.PerspectiveCamera,
				// except when using an AR-capable browser, the camera uses
				// the projection matrix provided from the device, so that the
				// perspective camera's depth planes and field of view matches
				// the physical camera on the device.
				camera = new THREE.ARPerspectiveCamera(
					vrDisplay,
					60,
					window.innerWidth / window.innerHeight,
					vrDisplay.depthNear,
					vrDisplay.depthFar
				);

				// VRControls is a utility from three.js that applies the device's
				// orientation/position to the perspective camera, keeping our
				// real world and virtual world in sync.
				vrControls = new THREE.VRControls(camera);

				// Bind our event handlers
				window.addEventListener('resize', onWindowResize, false);
				window.addEventListener('touchstart', onClick, false);
				canvas.addEventListener('click', onClick, false);

  				anchorManager = new THREE.ARAnchorManager(vrDisplay);

				// Kick off the render loop!
				update();
			}

			/**
			 * The render loop, called once per frame. Handles updating
			 * our scene and rendering.
			 */
			function update() {
				// Clears color from the frame before rendering the camera (arView) or scene.
				renderer.clearColor();

				// Render the device's camera stream on screen first of all.
				// It allows to get the right pose synchronized with the right frame.
				arView.render();

				// Update our camera projection matrix in the event that
				// the near or far planes have updated
				camera.updateProjectionMatrix();

				// From the WebVR API, populate `vrFrameData` with
  				// updated information for the frame
  				vrDisplay.getFrameData(vrFrameData);

				// Update our perspective camera's positioning
				vrControls.update();

				// If we have not added boxes yet, and we have positional
				// information applied to our camera (it can take a few seconds),
				// and the camera's Y position is not undefined or 0, create boxes
				if (!objectsAdded && !camera.position.y) {
					addObjects();
				}

				// Render our three.js virtual scene
				renderer.clearDepth();

				renderer.render(scene, camera);

				// Kick off the requestAnimationFrame to call this function
				// when a new VRDisplay frame is rendered
				vrDisplay.requestAnimationFrame(update);
			}

			/**
			 * On window resize, update the perspective camera's aspect ratio,
			 * and call `updateProjectionMatrix` so that we can get the latest
			 * projection matrix provided from the device
			 */
			function onWindowResize() {
				camera.aspect = window.innerWidth / window.innerHeight;
				camera.updateProjectionMatrix();
				renderer.setSize(window.innerWidth, window.innerHeight);
			}

			/**
			 * When clicking on the screen, create a cube at the user's
			 * current position.
			 */
			function onClick(event) {
				
				// addObject(event);

				var x = event.clientX / window.innerWidth;
				var y = event.clientY / window.innerHeight;

				// Send a ray from the point of click to the real world surface
				// and attempt to find a hit. `hitTest` returns an array of potential
				// hits.
				var hits = vrDisplay.hitTest(x, y);

				// If a hit is found, just use the first one
				if (hits && hits.length) {

				  	var hit = hits[0];

				    // Turn the model matrix from the VRHit into a
				    // THREE.Matrix4 so we can extract the position
				    // elements out so we can position the shadow mesh
				    // to be directly under our model. This is a complicated
				    // way to go about it to illustrate the process, and could
				    // be done by manually extracting the "Y" value from the
				    // hit matrix via `hit.modelMatrix[13]`
				    var matrix = new THREE.Matrix4();
				    var position = new THREE.Vector3();
				    matrix.fromArray(hit.modelMatrix);
				    position.setFromMatrixPosition(matrix);

				    var clickPosition = getPosition();

				    var geometry = new THREE.Geometry();
				    geometry.vertices.push(position);
				    geometry.vertices.push(clickPosition);

				    var ray = new THREE.Line(geometry, new THREE.LineBasicMaterial({color: 0xFF00FF, linewidth: 20}));
					scene.add(ray);

				}
			}

			function createLight() {
				var hemisphereLight = new THREE.HemisphereLight(0xffffff, 0x444444);
			    hemisphereLight.position.set(0, 300, 0);
			    scene.add(hemisphereLight);
			}

			function createSkybox() {

				// var path = "skybox/";

				// var urls = [path + "px.jpg", path + "nx.jpg",
				//		 	path + "py.jpg", path + "ny.jpg",
				//		 	path + "pz.jpg", path + "nz.jpg"];

				var path = "skyline/";
			
				var urls = [path + "rightcity.jpg", path + "leftcity.jpg",
						 	path + "topcity.jpg", path + "botcity.jpg",
						 	path + "frontcity.jpg", path + "backcity.jpg"];

				var envMap = THREE.ImageUtils.loadTextureCube(urls);

				var shader = THREE.ShaderLib["cube"];
				shader.uniforms["tCube"].value = envMap;
				var material = new THREE.ShaderMaterial({

					fragmentShader: shader.fragmentShader,
					vertexShader: shader.vertexShader,
					uniforms: shader.uniforms,
					side: THREE.BackSide
				});

				var mesh = new THREE.Mesh(new THREE.CubeGeometry(1000, 1000, 1000), material);
				scene.add(mesh);

			}

			function createObject() {
				var geometry = new THREE.ConeGeometry(0.05, 0.1, 16);
				var material = new THREE.MeshBasicMaterial({
					wireframe: true
				});
				object = new THREE.Mesh(geometry, material);
			}

			function getPosition() {

				// Fetch the pose data from the current frame
				var pose = vrFrameData.pose;

				// Convert the pose orientation and position into
				// THREE.Quaternion and THREE.Vector3 respectively
				var ori = new THREE.Quaternion(
					pose.orientation[0],
					pose.orientation[1],
					pose.orientation[2],
					pose.orientation[3]
				);

				var pos = new THREE.Vector3(
					pose.position[0],
					pose.position[1],
					pose.position[2]
				);

				var dirMtx = new THREE.Matrix4();
				dirMtx.makeRotationFromQuaternion(ori);

				var push = new THREE.Vector3(0, 0, -1.0);
				push.transformDirection(dirMtx);
				pos.addScaledVector(push, 0.125);

				return pos;
			}

			function addObject(event) {
				// If the user touched with 2 or more fingers, remove the latest model and
				// its anchor.
				if (objects.length > 0 && event.touches.length > 1) {
					anchorManager.remove(objects[0]);
					scene.remove(objects[0]);
					objects.splice(0, 1);
					return;
				}

				var pos = getPosition();

				// Clone our cube object and place it at the camera's
				// current position
				var objectClone = object.clone();
				scene.add(objectClone);
				objectClone.position.copy(pos);
				objectClone.quaternion.copy(ori);

				objects.push(objectClone);

				anchorManager.add(objectClone);
			}

			/**
			 * Once we have position information applied to our camera,
			 * create some boxes at the same height as the camera
			 */

			function addObjects() {

				var quantity = 3

				var angle = Math.PI * 2 * (1 / quantity);
				var geometry = new THREE.CubeGeometry(2, 2, 2);
				var material = new THREE.MeshBasicMaterial({
					wireframe: true
				});
				var cube = new THREE.Mesh(geometry, material);
				cube.position.set(Math.cos(angle) * OBJECT_DISTANCE, camera.position.y + 0.25, Math.sin(angle) * OBJECT_DISTANCE);
				scene.add(cube);
				objects.push(cube);

				var angle = Math.PI * 2 * (2 / quantity);
				var geometry = new THREE.CylinderGeometry(1, 1, 3, 8);
				var material = new THREE.MeshBasicMaterial({
					wireframe: true
				});
				var cylinder = new THREE.Mesh(geometry, material);
				cylinder.position.set(Math.cos(angle) * OBJECT_DISTANCE, camera.position.y - 2, Math.sin(angle) * OBJECT_DISTANCE);
				scene.add(cylinder);
				objects.push(cylinder);

				var angle = Math.PI * 2 * (3 / quantity);
				var geometry = new THREE.ConeGeometry(1, 3, 16);
				var material = new THREE.MeshBasicMaterial({
					wireframe: true
				});
				var cone = new THREE.Mesh(geometry, material);
				cone.position.set(Math.cos(angle) * OBJECT_DISTANCE, camera.position.y - 1.5, Math.sin(angle) * OBJECT_DISTANCE);
				scene.add(cone);
				objects.push(cone);

				// Flip this switch so that we only perform this once
				objectsAdded = true;
			}
		</script>
	</body>
</html>